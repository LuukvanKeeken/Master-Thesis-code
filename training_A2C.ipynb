{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from datetime import date\n",
    "\n",
    "from backpropamine_A2C import BP_RNetwork\n",
    "from BP_A2C.BP_A2C_agent import A2C_Agent\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment specific parameters\n",
    "env_name = 'CartPole-v0'\n",
    "n_runs = 5\n",
    "n_evaluations = 100\n",
    "max_steps = 200\n",
    "num_episodes = 1000\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2C hyperparameters\n",
    "entropy_coef = 0.03 \n",
    "value_pred_coef = 0.1 \n",
    "gammaR = 0.9\n",
    "max_grad_norm = 4.0\n",
    "batch_size = 128\n",
    "print_every = 10\n",
    "save_every = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam hyperparameters\n",
    "learning_rate = 1e-4 # For Adam optimizer\n",
    "l2_coef = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_seeds = np.load('rstdp_cartpole_stuff/seeds/training_seeds.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Directory BP_A2C/results/a2c_result_8_20231013_entropycoef_0.03_valuepredcoef_0.1_batchsize_128_maxsteps_200_maxgradnorm_4.0_gammaR_0.9_l2coef_0_learningrate_0.0001_numepisodes_1000 to store the results in\n"
     ]
    }
   ],
   "source": [
    "# Create Results Directory\n",
    "dirs = os.listdir('./BP_A2C/results/')\n",
    "if not any('a2c_result' in d for d in dirs):\n",
    "    result_id = 1\n",
    "else:\n",
    "    results = [d for d in dirs if 'a2c_result' in d]\n",
    "    result_id = len(results) + 1\n",
    "\n",
    "# Get today's date and add it to the results directory\n",
    "d = date.today()\n",
    "result_dir = 'BP_A2C/results/a2c_result_' + str(result_id) + \"_{}_entropycoef_{}_valuepredcoef_{}_batchsize_{}_maxsteps_{}_\\\n",
    "maxgradnorm_{}_gammaR_{}_l2coef_{}_learningrate_{}_numepisodes_{}\".format(\n",
    "    str(d.year) + str(d.month) + str(d.day), entropy_coef, value_pred_coef, batch_size, max_steps, max_grad_norm, gammaR,\n",
    "    l2_coef, learning_rate, num_episodes)\n",
    "os.mkdir(result_dir)\n",
    "print('Created Directory {} to store the results in'.format(result_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run # 0\n",
      "Batch size larger than 1 not implemented yet. Program will continue with batch size set to 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luuk/Desktop/testing/.venv/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/luuk/Desktop/testing/.venv/lib/python3.8/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'p' must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/luuk/Desktop/testing/training_A2C.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luuk/Desktop/testing/training_A2C.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(agent_net\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m\u001b[39m*\u001b[39mlearning_rate, eps\u001b[39m=\u001b[39m\u001b[39m1e-4\u001b[39m, weight_decay\u001b[39m=\u001b[39ml2_coef)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luuk/Desktop/testing/training_A2C.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m agent \u001b[39m=\u001b[39m A2C_Agent(env_name, seed, agent_net, entropy_coef, value_pred_coef, gammaR,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luuk/Desktop/testing/training_A2C.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                   max_grad_norm, max_steps, batch_size, num_episodes, optimizer, print_every,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luuk/Desktop/testing/training_A2C.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                   save_every, i_run, result_dir)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/luuk/Desktop/testing/training_A2C.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m smoothed_scores, scores, best_average, best_average_after \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mtrain_agent()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luuk/Desktop/testing/training_A2C.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# # policy_net = QNetwork(architecture, seed).to(device)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luuk/Desktop/testing/training_A2C.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# # target_net = QNetwork(architecture, seed).to(device)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luuk/Desktop/testing/training_A2C.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# policy_net = BP_RNetwork(4, 64, 2, seed).to(device)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luuk/Desktop/testing/training_A2C.ipynb#W6sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# smoothed_scores_dqn_all.append(smoothed_scores)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luuk/Desktop/testing/training_A2C.ipynb#W6sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# print(\"\")\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/testing/BP_A2C/BP_A2C_agent.py:94\u001b[0m, in \u001b[0;36mA2C_Agent.train_agent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m dist \u001b[39m=\u001b[39m policy_dist\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy() \n\u001b[1;32m     93\u001b[0m \u001b[39m# Sample from distribution to select action\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m action \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mchoice(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_outputs, p\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49msqueeze(dist))\n\u001b[1;32m     95\u001b[0m log_prob \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlog(policy_dist\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)[action])\n\u001b[1;32m     96\u001b[0m entropy \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mmean(dist) \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mlog(dist))\n",
      "File \u001b[0;32mmtrand.pyx:930\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'p' must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "smoothed_scores_dqn_all = []\n",
    "dqn_completion_after = []\n",
    "\n",
    "for i_run in range(1):\n",
    "    print(\"Run # {}\".format(i_run))\n",
    "    seed = int(training_seeds[i_run])\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    agent_net = BP_RNetwork(4, 64, 2, seed).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(agent_net.parameters(), lr=1.0*learning_rate, eps=1e-4, weight_decay=l2_coef)\n",
    "    agent = A2C_Agent(env_name, seed, agent_net, entropy_coef, value_pred_coef, gammaR,\n",
    "                      max_grad_norm, max_steps, batch_size, num_episodes, optimizer, print_every,\n",
    "                      save_every, i_run, result_dir)\n",
    "\n",
    "    smoothed_scores, scores, best_average, best_average_after = agent.train_agent()\n",
    "\n",
    "    # # policy_net = QNetwork(architecture, seed).to(device)\n",
    "    # # target_net = QNetwork(architecture, seed).to(device)\n",
    "    # policy_net = BP_RNetwork(4, 64, 2, seed).to(device)\n",
    "    # target_net = BP_RNetwork(4, 64, 2, seed).to(device)\n",
    "\n",
    "    # target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    # # optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)\n",
    "    # optimizer = optim.Adam(policy_net.parameters(), lr = learning_rate, weight_decay = l2_coef) \n",
    "    # agent = Agent(env_name, policy_net, target_net, architecture, batch_size,\n",
    "    #               replay_memory_size, discount_factor, eps_start, eps_end, eps_decay,\n",
    "    #               update_every, target_update_frequency, optimizer, learning_rate,\n",
    "    #               num_episodes, max_steps, i_run, result_dir, seed, tau)\n",
    "    \n",
    "    # smoothed_scores, scores, best_average, best_average_after = agent.train_agent()\n",
    "\n",
    "    # np.save(result_dir + '/scores_{}'.format(i_run), scores)\n",
    "    # np.save(result_dir + '/smoothed_scores_DQN_{}'.format(i_run), smoothed_scores)\n",
    "\n",
    "    # # save smoothed scores in list to plot later\n",
    "    # dqn_completion_after.append(best_average_after)\n",
    "    # smoothed_scores_dqn_all.append(smoothed_scores)\n",
    "    # print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHEN EVALUATING, TAKE THE ARGMAX INSTEAD OF SAMPLING"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
